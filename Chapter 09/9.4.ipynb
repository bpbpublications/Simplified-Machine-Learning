import numpy as np

class UCB1:
    def __init__(self, num_arms):
        self.num_arms = num_arms
        self.total_rewards = np.zeros(num_arms)
        self.num_pulls = np.zeros(num_arms)
        self.total_pulls = 0
        
    def select_action(self):
        if 0 in self.num_pulls:
            # Pull each arm at least once
            return np.where(self.num_pulls == 0)[0][0]
        
        ucb_values = self.total_rewards / self.num_pulls + np.sqrt(2 * np.log(self.total_pulls) / self.num_pulls)
        return np.argmax(ucb_values)
    
    def update(self, action, reward):
        self.total_rewards[action] += reward
        self.num_pulls[action] += 1
        self.total_pulls += 1

# Example usage:
num_arms = 5
ucb_agent = UCB1(num_arms)

# Run multiple episodes
num_episodes = 1000
for _ in range(num_episodes):
    action = ucb_agent.select_action()
    # Simulate a reward based on the chosen action
    reward = np.random.normal(loc=0.5, scale=0.1) if action == 0 else np.random.normal(loc=0.3, scale=0.1)
    ucb_agent.update(action, reward)

# Print the estimated reward for each arm
for arm in range(num_arms):
    print(f"Estimated reward for arm {arm}: {ucb_agent.total_rewards[arm] / ucb_agent.num_pulls[arm]}")


 
