import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

# Sample data with multiple independent variables (X1, X2, X3) and a dependent variable (Y)
X = np.array([[1, 2, 3], [2, 3, 4], [3, 4, 5], [4, 5, 6], [5, 6, 7]])
Y = np.array([5, 8, 11, 14, 17])

# Split the data into training and testing sets
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

# Create a linear regression model
model = LinearRegression()

# Fit the model to the training data
model.fit(X_train, Y_train)

# Make predictions using the trained model
Y_pred = model.predict(X_test)

# Calculate the mean squared error (MSE) to evaluate the model's performance
mse = mean_squared_error(Y_test, Y_pred)

# Get the regression coefficients (intercept and slopes)
intercept = model.intercept_
coefficients = model.coef_

print("Intercept (β0):", intercept)
print("Coefficients (β1, β2, β3):", coefficients)
print("Mean Squared Error (MSE):", mse)

# Plot the original data points and the regression plane
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.scatter(X_test[:, 0], X_test[:, 1], Y_test, color='blue', label='Actual Data Points')
ax.scatter(X_test[:, 0], X_test[:, 1], Y_pred, color='red', label='Predicted Data Points')
ax.set_xlabel('X1-axis')
ax.set_ylabel('X2-axis')
ax.set_zlabel('Y-axis')
ax.legend()
ax.set_title('Linear Regression Plane')

plt.show()


 

