# Import necessary libraries
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report

# Sample text data
corpus = [
    'This is a positive example.',
    'I love working with machine learning.',
    'Text data pre-processing is important for ML.',
    'Negative examples can be challenging too.',
    'Machine learning models learn from data.'
]

# Corresponding labels (0 for negative, 1 for positive)
labels = [1, 1, 1, 0, 1]

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(corpus, labels, test_size=0.2, random_state=42)

# Text vectorization using Bag-of-Words (CountVectorizer)
vectorizer = CountVectorizer()
X_train_vectorized = vectorizer.fit_transform(X_train)
X_test_vectorized = vectorizer.transform(X_test)

# Train a simple classifier (Naive Bayes in this case)
classifier = MultinomialNB()
classifier.fit(X_train_vectorized, y_train)

# Make predictions on the test set
predictions = classifier.predict(X_test_vectorized)

# Evaluate the classifier
accuracy = accuracy_score(y_test, predictions)
report = classification_report(y_test, predictions)

# Print the results
print(f"Accuracy: {accuracy:.2f}")
print("\nClassification Report:\n", report)



 
